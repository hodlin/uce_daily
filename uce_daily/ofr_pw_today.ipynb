{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import pytz\n",
    "import time\n",
    "import calendar\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "\n",
    "from uce_resources import get_mms_data, get_applied_forecast, get_current_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings.sites import ceg as sites_list\n",
    "\n",
    "today = dt.datetime.today() #- dt.timedelta(days=1)\n",
    "print(today)\n",
    "target_year = today.year\n",
    "target_month = today.month\n",
    "forecasts_types = ['real']\n",
    "\n",
    "target_folder = 'data/results/{}-{:0>2}/'.format(target_year, target_month)\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "# sites_list = ['Dibrovka']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "imported_module = importlib.import_module(\"get_current_production_powermeter\")\n",
    "importlib.reload(imported_module)\n",
    "from get_current_production_powermeter import OperativeProduction\n",
    "from settings.apis import BORD_API_SETTINGS\n",
    "\n",
    "PowermeterDataGetter = OperativeProduction(**BORD_API_SETTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy.pool import NullPool\n",
    "from sqlalchemy.sql import select, and_\n",
    "from settings.db import DO_URL\n",
    "\n",
    "engine_source = create_engine(DO_URL, poolclass=NullPool)\n",
    "metadata_source = MetaData()\n",
    "metadata_source.reflect(bind=engine_source)\n",
    "\n",
    "\n",
    "from settings.db import WAREHOSUE_URL\n",
    "\n",
    "engine_warehouse = create_engine(WAREHOSUE_URL, poolclass=NullPool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_data = list()\n",
    "\n",
    "with engine_source.connect() as connection:\n",
    "        \n",
    "    for site in sites_list:\n",
    "        start = time.time()\n",
    "        # print('-'*50)\n",
    "        # print(site)\n",
    "        site_data = dict()\n",
    "\n",
    "        sites_table = metadata_source.tables['sites']\n",
    "        list_to_select = [\n",
    "            sites_table.c.id, \n",
    "            sites_table.c.legal_entity, \n",
    "            sites_table.c.location, \n",
    "            sites_table.c.region, \n",
    "            sites_table.c.cluster,\n",
    "            sites_table.c.installed_capacity_dc,\n",
    "            sites_table.c.grid_capacity,\n",
    "            sites_table.c.w_code\n",
    "            ]\n",
    "        query = select(list_to_select).where(sites_table.c.displayable_name == site)\n",
    "        site_id_response = connection.execute(query).fetchall()[0]\n",
    "\n",
    "        site_id = site_id_response[0]\n",
    "        legal_entity_id = site_id_response[1]\n",
    "        location = site_id_response[2]\n",
    "        region = site_id_response[3]\n",
    "        cluster = site_id_response[4]\n",
    "        capacity_dc = site_id_response[5]\n",
    "        grid_capacity = site_id_response[6]\n",
    "        w_code = site_id_response[7]\n",
    "        \n",
    "        with engine_warehouse.connect() as connection_warehouse:\n",
    "            query = f\"\"\"\n",
    "            SELECT grid_capacity from dim_site\n",
    "            WHERE site_name = '{site}';\n",
    "            \"\"\"\n",
    "            response = connection_warehouse.execute(query).fetchall()[0]\n",
    "            \n",
    "        grid_capacity = response[0]\n",
    "\n",
    "        latitude, longitude = map(float, location.replace('(', '').replace(')', '').split(','))\n",
    "\n",
    "        powermeter_data = PowermeterDataGetter.get_data(w_code, today)\n",
    "        powermeter_data.columns= ['yield']\n",
    "        # if powermeter_data is not None and len(powermeter_data) > 0:\n",
    "        mms_data = powermeter_data\n",
    "            #print(mms_data.loc[mms_data.index.intersection(inverters_data.index)])\n",
    "            #raise KeyboardInterrupt\n",
    "\n",
    "        first_date = today- dt.timedelta(days=1)\n",
    "        last_date = dt.date(\n",
    "            target_year, \n",
    "            target_month, \n",
    "            calendar.monthrange(target_year, target_month)[1]\n",
    "        ) + dt.timedelta(days=7)\n",
    "        # print(f\"first_date: {first_date} last_date: {last_date}\")\n",
    "\n",
    "        applied_forecast = get_applied_forecast(\n",
    "            site_id, \n",
    "            first_date,\n",
    "            last_date,\n",
    "            connection=connection, \n",
    "            db_table=metadata_source.tables['forecasting_data']\n",
    "        )\n",
    "\n",
    "        applied_forecast.columns = ['forecast']\n",
    "        # print('Forecast data of | {} records |'.format(len(applied_forecast)))\n",
    "        # print('applied_forecast.index.min:', applied_forecast.index.min())\n",
    "        # print('applied_forecast.index.max:',applied_forecast.index.max())\n",
    "        \n",
    "\n",
    "        forecast = applied_forecast\n",
    "        forecast_data = pd.concat([forecast, mms_data.loc[mms_data.index >= forecast.index.min()]], axis=1, join='outer').reindex(columns=['yield', 'forecast'])\n",
    "\n",
    "        site_series = pd.Series(index=forecast_data.index, data=site)\n",
    "        latitude_series = pd.Series(index=forecast_data.index, data=latitude)\n",
    "        longitude_series = pd.Series(index=forecast_data.index, data=longitude)\n",
    "        region_series = pd.Series(index=forecast_data.index, data=region)\n",
    "        cluster_series = pd.Series(index=forecast_data.index, data=cluster)\n",
    "        capacity_dc_series = pd.Series(index=forecast_data.index, data=capacity_dc)\n",
    "        grid_capacity_series = pd.Series(index=forecast_data.index, data=grid_capacity)\n",
    "\n",
    "        site_data = pd.concat([\n",
    "                    site_series, \n",
    "                    latitude_series, \n",
    "                    longitude_series,\n",
    "                    region_series, \n",
    "                    cluster_series,\n",
    "                    capacity_dc_series,\n",
    "                    grid_capacity_series\n",
    "                ], \n",
    "                axis=1\n",
    "            )\n",
    "        site_data.columns = ['site', 'latitude', 'longitude', 'region', 'cluster', 'capacity_dc', 'grid_capacity']                       \n",
    "        site_data['date'] = site_data.index.strftime('%Y-%m-%d')\n",
    "        site_data['hour'] = site_data.index.hour + 1\n",
    "        site_data['datetime'] = site_data.index.strftime('%Y-%m-%dT%H:%M')\n",
    "        site_data['datetime_tz'] = site_data.index.tz_localize(pytz.utc).tz_convert(pytz.timezone('europe/kiev')).strftime('%Y-%m-%dT%H:%M%z')\n",
    "        \n",
    "        site_data = pd.concat([site_data, forecast_data], axis=1)\n",
    "\n",
    "        site_data['error'] = site_data['yield'] - site_data['forecast']\n",
    "        site_data['error_positive'] = site_data['error'].apply(lambda x: x * (x >= 0))\n",
    "        site_data['error_negative'] = site_data['error'].apply(lambda x: x * (x < 0))\n",
    "        site_data['error_abs'] = site_data['error'].apply(abs)\n",
    "        site_data['error_type'] = site_data['error'].apply(lambda x: 'negative' if x < 0 else 'positive')\n",
    "        \n",
    "        sites_data.append(site_data)\n",
    "        end = time.time()\n",
    "\n",
    "        print('{}: Ğ¾Ğº! Processing took {} seconds'.format(site, round(end - start, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(sites_data, ignore_index=True).fillna(0)\n",
    "data = data.drop_duplicates(keep='first')\n",
    "data.to_csv(target_folder + 'mart_operative_forecasting_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_26 = data.copy()\n",
    "# data_26 = data.loc[data.date == '2022-03-26']\n",
    "site = 'Myroliubivka'\n",
    "print(data_26.loc[(data_26.site == site) & (data_26['yield'] <= 0) & (data_26['forecast'] < 0)])\n",
    "data_26.loc[(data_26.site == site) & (data_26['yield'] <= 0) & (data_26['forecast'] < 0)][['yield', 'forecast']].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting data to data mart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = data.copy()\n",
    "tuples_full = [tuple(x) for x in df_full.to_numpy()]\n",
    "# print(tuples_full[-2:])\n",
    "columns = list(df_full.columns)\n",
    "\n",
    "columns_unique = [columns[0], *columns[5:7]]\n",
    "# print(columns_unique)\n",
    "\n",
    "df_update = df_full.copy().drop(columns=columns_unique)\n",
    "tuples_update = [tuple(x) for x in df_update.to_numpy()]\n",
    "columns_update = list(df_update.columns)\n",
    "# print(columns_update)\n",
    "# SQL query to execute\n",
    "query_1 = 'INSERT INTO mart_operative_forecasting_result({}) VALUES {}'.format(','.join(columns), str(tuples_full).replace('[', '').replace(']', ''))\n",
    "query_2 = '''\n",
    "ON CONFLICT (site, date, hour) \n",
    "DO UPDATE SET\n",
    "latitude = excluded.latitude,\n",
    "longitude = excluded.longitude,\n",
    "region = excluded.region,\n",
    "cluster = excluded.cluster,\n",
    "datetime = excluded.datetime,\n",
    "datetime_tz = excluded.datetime_tz,\n",
    "yield = excluded.yield,\n",
    "forecast = excluded.forecast,\n",
    "error = excluded.error,\n",
    "error_positive = excluded.error_positive,\n",
    "error_negative = excluded.error_negative,\n",
    "error_abs = excluded.error_abs,\n",
    "error_type = excluded.error_type,\n",
    "capacity_dc = excluded.capacity_dc,\n",
    "grid_capacity = excluded.grid_capacity;'''\n",
    "# print(query_1, query_2)\n",
    "with engine_warehouse.connect() as connection:\n",
    "    connection.execute(query_1 + '\\n' + query_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uce_daily",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "63b635d65d60b1811ede0cf7a8833095bfcf77b57869dea97c846496b0c0212b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
