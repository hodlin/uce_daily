{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import calendar\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, MetaData, desc\n",
    "from sqlalchemy.sql import select, and_, or_, not_\n",
    "from sqlalchemy.pool import NullPool\n",
    "\n",
    "from settings.db import DO_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\n.kozelets\\AppData\\Local\\Temp\\ipykernel_11860\\3866986131.py:3: SAWarning: Did not recognize type 'point' of column 'location'\n",
      "  metadata.reflect(bind=engine)\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(DO_URL, poolclass=NullPool)\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "\n",
    "\n",
    "def clean_file(file_name):\n",
    "    output_file = io.StringIO()\n",
    "    with open(file_name, encoding='utf8') as read_file:\n",
    "        lines = read_file.readlines()\n",
    "        for line in lines:\n",
    "            line = list(line)\n",
    "            date = line[:16]\n",
    "            line[0:4] = date[6:10]\n",
    "            line[4:8] = date[2:6]\n",
    "            line[8:10] = date[0:2]\n",
    "            #line[10] = '-'\n",
    "            line[14] = '3'\n",
    "            del line[16:24]\n",
    "            line = ''.join(line)\n",
    "            line = line.replace('.', '-')\n",
    "            line = line.replace('\\u00A0', '')\n",
    "            line = line.replace('\\u0412', '')\n",
    "            #print(line)\n",
    "            output_file.write(line)\n",
    "    output_file.seek(0)\n",
    "    #print(output_file.getvalue())\n",
    "    return output_file\n",
    "\n",
    "\n",
    "def get_record_index(site_id, date, table, connection):\n",
    "    index = None\n",
    "\n",
    "    query_1 = select([table.c.id, table.c.completed]).where(and_(table.c.site == site_id, table.c.year == date.year, table.c.month == date.month))\n",
    "    record_to_update = connection.execute(query_1).fetchall()\n",
    "\n",
    "    if record_to_update:\n",
    "        return record_to_update[0][0], True\n",
    "    else:\n",
    "        max_index_response = connection.execute('SELECT MAX(id) FROM public.{0}'.format(table))\n",
    "        index = list(max_index_response)[0][0]\n",
    "        index = 1 if index is None else int(index) + 1\n",
    "        return index, False\n",
    "\n",
    "\n",
    "def get_site_id(site_name, connection):\n",
    "    query = 'SELECT id FROM public.sites where displayable_name = \\'{0}\\''.format(site_name)\n",
    "    # print(query)\n",
    "    site_id_response = connection.execute(query)\n",
    "    site_id = list(site_id_response)[0][0]\n",
    "    return site_id\n",
    "\n",
    "def get_time_index(start_date, last_data_day, timezone='utc'):\n",
    "    start = dt.datetime(year=start_date.year, month=start_date.month, day=1, hour=0, minute=30)\n",
    "    last_month_day_calendar = calendar.monthrange(start_date.year, start_date.month)[-1]\n",
    "    last_month_day_data = last_data_day\n",
    "    if last_month_day_data == last_month_day_calendar:\n",
    "        year = start_date.year\n",
    "        month = start_date.month + 1 \n",
    "        if month == 13:\n",
    "            month = 1\n",
    "            year = year + 1\n",
    "        end = dt.datetime(year=year, month=month, day=1, hour=0, minute=30) - dt.timedelta(hours=1)\n",
    "    else:\n",
    "        end = dt.datetime(year=start_date.year, month=start_date.month, day=last_month_day_data + 1, hour=0, minute=30)\n",
    "        end = end - dt.timedelta(hours=1)\n",
    "    index_in_kyiv = pd.date_range(start=start, end=end, freq='1H', tz='europe/kiev')\n",
    "    index_in_utc = index_in_kyiv.tz_convert('utc').tz_localize(None)\n",
    "    if timezone == 'utc':\n",
    "        return index_in_utc\n",
    "    elif timezone == 'europe/kiev':\n",
    "        return index_in_kyiv.tz_localize(None)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_site_data(filename, date):\n",
    "    data_header = ['datetime', 'generation_v1', 'generation_v2', 'generation_v3', 'consumption_v1', 'consumption_v2', 'consumption_v3']\n",
    "    data_stream = clean_file(filename)\n",
    "    data = pd.read_csv(data_stream, sep=';', decimal=',', encoding='utf8', \n",
    "                        skiprows=1, header=None, names=data_header, na_values=['f', 'ff'])\n",
    "    data['day'] = data['datetime'].apply(lambda datetime: int(datetime[8:10]))\n",
    "    print(data)\n",
    "    index_in_utc = get_time_index(date, data['day'].max())\n",
    "    #print(squized.tail(52))\n",
    "    data.index = index_in_utc\n",
    "    data.index.name = 'timestamp_utc'\n",
    "    data = data.drop(['datetime', 'day'], axis=1)\n",
    "    data = data.dropna(how='all')\n",
    "    site_data = dict()\n",
    "    site_data['generation_v1'] = list(data['generation_v1'].astype(int)) if not data['generation_v1'].isnull().values.any() else list()\n",
    "    site_data['generation_v2'] = list(data['generation_v2'].astype(int)) if not data['generation_v2'].isnull().values.any() else list()\n",
    "    site_data['generation_v3'] = list(data['generation_v3'].astype(int)) if not data['generation_v3'].isnull().values.any() else list()\n",
    "    site_data['consumption_v1'] = list(data['consumption_v1'].astype(int)) if not data['consumption_v1'].isnull().values.any() else list()\n",
    "    site_data['consumption_v2'] = list(data['consumption_v2'].astype(int)) if not data['consumption_v2'].isnull().values.any() else list()\n",
    "    site_data['consumption_v3'] = list(data['consumption_v3'].astype(int)) if not data['consumption_v3'].isnull().values.any() else list()\n",
    "    site_data['total_v1'] = [gen - cons for gen, cons in zip(site_data['generation_v1'], site_data['consumption_v1'])]\n",
    "    site_data['total_v2'] = [gen - cons for gen, cons in zip(site_data['generation_v2'], site_data['consumption_v2'])]\n",
    "    site_data['total_v3'] = [gen - cons for gen, cons in zip(site_data['generation_v3'], site_data['consumption_v3'])]\n",
    "    site_data['timestamps_utc'] = list(data.index.to_pydatetime())\n",
    "    site_data['year'] = date.year\n",
    "    site_data['month'] = date.month\n",
    "    completed = (max(site_data['timestamps_utc']).day == calendar.monthrange(date.year, date.month)[1]) \\\n",
    "                & (bool(site_data['total_v3']))\n",
    "    site_data['completed'] = completed\n",
    "    return site_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "target_period = '2022-01_1-20_'\n",
    "mms_yield_data_dir = 'data/mms/' + target_period + '/'\n",
    "march_dlst_days = {2019: 31, 2020: 29, 2021: 28, 2022: 27}\n",
    "\n",
    "date = target_period.split('_')[0]\n",
    "date = dt.datetime.strptime(date, '%Y-%m')\n",
    "print(date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "------------------------------\n",
      "Afanasiivka\n",
      "             datetime  generation_v1  generation_v2  generation_v3  \\\n",
      "0    2022-01-01 00:30            0.0            NaN            NaN   \n",
      "1    2022-01-01 01:30            0.0            NaN            NaN   \n",
      "2    2022-01-01 02:30            0.0            NaN            NaN   \n",
      "3    2022-01-01 03:30            0.0            NaN            NaN   \n",
      "4    2022-01-01 04:30            0.0            NaN            NaN   \n",
      "..                ...            ...            ...            ...   \n",
      "739  2022-01-31 19:30            NaN            NaN            NaN   \n",
      "740  2022-01-31 20:30            NaN            NaN            NaN   \n",
      "741  2022-01-31 21:30            NaN            NaN            NaN   \n",
      "742  2022-01-31 22:30            NaN            NaN            NaN   \n",
      "743  2022-01-31 23:30            NaN            NaN            NaN   \n",
      "\n",
      "     consumption_v1  consumption_v2  consumption_v3  day  \n",
      "0              38.0             NaN             NaN    1  \n",
      "1              37.0             NaN             NaN    1  \n",
      "2              37.0             NaN             NaN    1  \n",
      "3              37.0             NaN             NaN    1  \n",
      "4              38.0             NaN             NaN    1  \n",
      "..              ...             ...             ...  ...  \n",
      "739             NaN             NaN             NaN   31  \n",
      "740             NaN             NaN             NaN   31  \n",
      "741             NaN             NaN             NaN   31  \n",
      "742             NaN             NaN             NaN   31  \n",
      "743             NaN             NaN             NaN   31  \n",
      "\n",
      "[744 rows x 8 columns]\n",
      "Columns length:| 480 | 480 | 0 | 0 | 480 | 0 | 0 |\n",
      "Ok!\n",
      "Database record updated!\n"
     ]
    }
   ],
   "source": [
    "data_files = [f for f in os.listdir(mms_yield_data_dir) if os.path.isfile(os.path.join(mms_yield_data_dir, f)) and f[-3:] == 'csv']\n",
    "mms_yield_files = dict()\n",
    "\n",
    "for data_file in data_files:\n",
    "    site = data_file.split('_')[0].replace('-', '_')\n",
    "    mms_yield_files.update({site: data_file})\n",
    "print(len(mms_yield_files.keys()))\n",
    "\n",
    "#mms_yield_sites = ['Afanasiivka']\n",
    "\n",
    "for site in mms_yield_files.keys():\n",
    "    print('-'*30)\n",
    "    print(site)\n",
    "    \n",
    "    site_data = get_site_data(mms_yield_data_dir + mms_yield_files[site], date)\n",
    "\n",
    "    #complete_period = prices.index.max().day == calendar.monthrange(date.year, date.month)[1]\n",
    "    print('Columns length:| {} | {} | {} | {} | {} | {} | {} |'.format(len(site_data['timestamps_utc']),\n",
    "                                                                       len(site_data['generation_v1']),\n",
    "                                                                       len(site_data['generation_v2']),\n",
    "                                                                       len(site_data['generation_v3']),\n",
    "                                                                       len(site_data['consumption_v1']),\n",
    "                                                                       len(site_data['consumption_v2']),\n",
    "                                                                       len(site_data['consumption_v3']),\n",
    "                                                                       len(site_data['total_v1']),\n",
    "                                                                       len(site_data['total_v2']),\n",
    "                                                                       len(site_data['total_v3'])))\n",
    "    print('Ok!')\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        table = metadata.tables['mms_data']\n",
    "        site_data['site'] = get_site_id(site, connection)\n",
    "        site_data['id'], to_update = get_record_index(site_data['site'], date, table, connection)\n",
    "\n",
    "        if to_update:\n",
    "            update_statement = table.update().values(**site_data).where(table.c.id == site_data['id'])\n",
    "            updated_id = connection.execute(update_statement)\n",
    "            print('Database record updated!')\n",
    "        else:\n",
    "            insert_statement = table.insert().values(**site_data)\n",
    "            inserted_id = connection.execute(insert_statement)\n",
    "            print('Data inserted to database'.format(inserted_id))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b590406a18f73ebac67bec6afe08252f008dd710ee6ef1e619f4e48db3f0dd14"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
