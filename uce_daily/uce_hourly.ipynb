{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "import calendar\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "from uce_resources import get_site_id, get_mms_data, get_applied_forecast, get_prices, get_green_tariff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings.sites import ceg_ as sites_list\n",
    "\n",
    "target_year = 2023\n",
    "target_month = 8\n",
    "forecasts_types = ['real', 'naive', 'zero', 'increased_10_forecast_data', 'increased_20_forecast_data', 'increased_30_forecast_data', \n",
    "                   'increased_40_forecast_data', 'decreased_10_forecast_data']\n",
    "\n",
    "target_folder = 'data/results/{}-{:0>2}/'.format(target_year, target_month)\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "# sites_list = ['Bar', 'Balky']\n",
    "sites_data = dict.fromkeys(sites_list)\n",
    "print(sites_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy.pool import NullPool\n",
    "from sqlalchemy.sql import select\n",
    "from settings.db import DO_URL\n",
    "\n",
    "engine = create_engine(DO_URL, poolclass=NullPool)\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    prices = get_prices(target_year, target_month, connection, metadata.tables['electricity_market_prices'], currency='UAH')\n",
    "\n",
    "# price_dir = 'data/results/2022-10/'\n",
    "# price_file = 'prices_2022_10_1-25.xlsx'\n",
    "# prices = pd.read_excel(price_dir + price_file, index_col= 0)\n",
    "\n",
    "min_price_day = (prices.index.min() + dt.timedelta(days=1)).day\n",
    "max_price_day = prices.index.max().day\n",
    "\n",
    "start_date = dt.date(year=target_year, month=target_month, day=min_price_day)\n",
    "end_date = dt.date(year=target_year, month=target_month, day=max_price_day)\n",
    "print(start_date, end_date)\n",
    "\n",
    "prices.to_excel(target_folder + 'prices_{}_{}_{}-{}.xlsx'.format(target_year, target_month, min_price_day, max_price_day))\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with engine.connect() as connection:\n",
    "        \n",
    "    for site in sites_data.keys():\n",
    "        start = time.time()\n",
    "        print('-'*50)\n",
    "        print(site)\n",
    "        site_data = dict()\n",
    "        site_data['site'] = site\n",
    "        site_data['site_id'], site_data['legal_entity'] = get_site_id(site, connection, \n",
    "                                                                      metadata.tables['sites'],\n",
    "                                                                      include_legal_entity_id=True)\n",
    "\n",
    "        site_data['green_tariff'] = get_green_tariff(site_data['site_id'], dt.date(year=target_year, month=target_month, day=1),\n",
    "                                                     connection, metadata.tables['green_tariffs'], currency='UAH')\n",
    "        print('Green tariff: {}'.format(site_data['green_tariff']))\n",
    "        \n",
    "        first_date = dt.date(target_year, target_month, 1)\n",
    "        last_date = dt.date(target_year, target_month, calendar.monthrange(target_year, target_month)[1])\n",
    "\n",
    "        mms_data, site_data['mms_version'] = get_mms_data(site_data['site_id'], \n",
    "                                                          target_year, target_month, \n",
    "                                                          connection, metadata.tables['mms_data'], include_prev=True,)\n",
    "        # print(mms_data)\n",
    "        print('MMS data | {} version | of | {} records |'.format(site_data['mms_version'], len(mms_data)))\n",
    "        \n",
    "        applied_forecast = get_applied_forecast(site_data['site_id'], start_date, end_date, \n",
    "                                                connection=connection, db_table=metadata.tables['forecasting_data'])\n",
    "        print('Forecast data of | {} records |'.format(len(applied_forecast)))\n",
    "\n",
    "        site_data['real_forecast_data'] = pd.concat([mms_data, applied_forecast], axis=1, join='inner')\n",
    "        print('Real forecast data prepared')\n",
    "\n",
    "\n",
    "        raw_forecast = get_applied_forecast(site_data['site_id'], start_date, end_date, \n",
    "                                            connection=connection, db_table=metadata.tables['forecasting_data'],\n",
    "                                            forecast_type='forecast_applied_raw')\n",
    "        print('Raw forecast data of | {} records |'.format(len(raw_forecast)))\n",
    " \n",
    "        \n",
    "        site_data['raw_forecast_data'] = pd.concat([mms_data, raw_forecast], axis=1, join='inner')\n",
    "        print('Raw forecast data prepared')\n",
    "\n",
    "\n",
    "\n",
    "        increased_10_forecast_data = raw_forecast * 1.1\n",
    "        print('increased_10 forecast data of | {} records |'.format(len(increased_10_forecast_data)))\n",
    "        \n",
    "        site_data['increased_10_forecast_data'] = pd.concat([mms_data, increased_10_forecast_data], axis=1, join='inner')\n",
    "        print('increased_10 forecast data prepared')\n",
    "\n",
    "\n",
    "        increased_20_forecast_data = raw_forecast * 1.2\n",
    "        print('increased_20 forecast data of | {} records |'.format(len(increased_20_forecast_data)))\n",
    "        \n",
    "        site_data['increased_20_forecast_data'] = pd.concat([mms_data, increased_20_forecast_data], axis=1, join='inner')\n",
    "        print('increased_20 forecast data prepared')\n",
    "\n",
    "\n",
    "        increased_30_forecast_data = raw_forecast * 1.3\n",
    "        print('increased_30 forecast data of | {} records |'.format(len(increased_30_forecast_data)))\n",
    "        \n",
    "        site_data['increased_30_forecast_data'] = pd.concat([mms_data, increased_30_forecast_data], axis=1, join='inner')\n",
    "        print('increased_30 forecast data prepared')\n",
    "\n",
    "\n",
    "        increased_40_forecast_data = raw_forecast * 1.4\n",
    "        print('increased_40 forecast data of | {} records |'.format(len(increased_40_forecast_data)))\n",
    "\n",
    "        # raw_forecast.index=pd.to_datetime(raw_forecast.index)\n",
    "        # mask=(raw_forecast.index.time >= pd.to_datetime('07:30:00').time()) & (raw_forecast.index.time >= pd.to_datetime('11:30:00').time())\n",
    "        # increased_40_forecast_data=raw_forecast.copy()\n",
    "        # increased_40_forecast_data.loc[mask, 'forecast [kWh]'] *=1.2\n",
    "        # print('increased_40 forecast data of | {} records |'.format(len(increased_40_forecast_data)))\n",
    "        \n",
    "        site_data['increased_40_forecast_data'] = pd.concat([mms_data, increased_40_forecast_data], axis=1, join='inner')\n",
    "        print('increased_40 forecast data prepared')\n",
    "\n",
    "\n",
    "        decreased_10_forecast_data = raw_forecast * 0.9\n",
    "        print('decreased_10 forecast data of | {} records |'.format(len(decreased_10_forecast_data)))\n",
    "        \n",
    "        site_data['decreased_10_forecast_data'] = pd.concat([mms_data, decreased_10_forecast_data], axis=1, join='inner')\n",
    "        print('decreased_10 forecast data prepared')\n",
    "\n",
    "\n",
    "        site_data['zero_forecast_data'] = pd.concat([mms_data, applied_forecast * 0], axis=1, join='inner')\n",
    "        print('Zero forecast data prepared')\n",
    "\n",
    "        naive_forecast_data = pd.concat([mms_data, mms_data.shift(48)], axis=1, join='inner').dropna(axis=0, how='any')\n",
    "        naive_forecast_data.columns = ['yield [kWh]', 'forecast [kWh]']\n",
    "        naive_forecast_data['forecast [kWh]'] = naive_forecast_data['forecast [kWh]'].astype(int)\n",
    "        site_data['naive_forecast_data'] = naive_forecast_data\n",
    "        print('Naive forecast data prepared')\n",
    "        \n",
    "        sites_data.update({site: site_data})\n",
    "        end = time.time()\n",
    "\n",
    "        print('Processing took {} seconds'.format(round(end - start, 2)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unbalance cost estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['site', 'first_date', 'last_date', 'hour', 'region', 'cluster',\n",
    "            'forecast_type','revenue [UAH]', \n",
    "            'error_u [kWh]', 'error_u [%]',\n",
    "            'error_u (excess) [kWh]',\n",
    "            'error_u (shortage) [kWh]',\n",
    "            'cieq_641_rule (excess) [UAH]', \n",
    "            'cieq_641_rule (shortage) [UAH]', \n",
    "            'cieq_641_rule (net) [UAH]',\n",
    "            'cieq_641_rule* [UAH]', \n",
    "            'cieq_641_rule_positive* [UAH]', 'cieq_641_rule_negative* [UAH]']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "daily_indexes = list()\n",
    "\n",
    "for day in range(1, calendar.monthrange(target_year, target_month)[-1] + 1):\n",
    "    start = dt.datetime(year=target_year, month=target_month, day=day, hour=0, minute=30)\n",
    "    end = dt.datetime(year=target_year, month=target_month, day=day, hour=23, minute=30)\n",
    "    index_in_kyiv = pd.date_range(start=start, end=end, freq='1H', tz='europe/kiev')\n",
    "    index_in_utc = index_in_kyiv.tz_convert('utc').tz_localize(None)\n",
    "    daily_indexes.append(index_in_utc)\n",
    "\n",
    "print(len(daily_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(daily_indexes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "imported_module = importlib.import_module(\"uce_resources\")\n",
    "importlib.reload(imported_module)\n",
    "from uce_resources import make_results_hourly\n",
    "\n",
    "results_real = pd.DataFrame(columns=columns)\n",
    "results_raw = pd.DataFrame(columns=columns)\n",
    "results_naive = pd.DataFrame(columns=columns)\n",
    "results_zero = pd.DataFrame(columns=columns)\n",
    "results_increased_10 = pd.DataFrame(columns=columns)\n",
    "results_increased_20 = pd.DataFrame(columns=columns)\n",
    "results_increased_30 = pd.DataFrame(columns=columns)\n",
    "results_increased_40 = pd.DataFrame(columns=columns)\n",
    "results_decreased_10 = pd.DataFrame(columns=columns)\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    for site in sites_data.keys():\n",
    "        \n",
    "        sites_table = metadata.tables['sites']\n",
    "        list_to_select = [\n",
    "            sites_table.c.id,\n",
    "            sites_table.c.region, \n",
    "            sites_table.c.cluster\n",
    "            ]\n",
    "        query = select(list_to_select).where(sites_table.c.displayable_name == site)\n",
    "        site_id_response = connection.execute(query).fetchall()[0]\n",
    "\n",
    "        site_id = site_id_response[0]\n",
    "        region = site_id_response[1]\n",
    "        cluster = site_id_response[2]\n",
    "\n",
    "\n",
    "        for index in daily_indexes:\n",
    "            # print(sites_data[site]['real_forecast_data'])\n",
    "            result_real = make_results_hourly(sites_data[site], 'real', prices, index, region, cluster)\n",
    "            # print(result_real)\n",
    "            if not result_real is None:\n",
    "                results_real = results_real.append(result_real, ignore_index=True)\n",
    "\n",
    "            result_raw = make_results_hourly(sites_data[site], 'raw', prices, index, region, cluster)\n",
    "            # print(result_raw)\n",
    "            if not result_raw is None:\n",
    "                results_raw = results_raw.append(result_raw, ignore_index=True)    \n",
    "\n",
    "            result_naive = make_results_hourly(sites_data[site], 'naive', prices, index, region, cluster)      \n",
    "            #print(result_naive)\n",
    "            if not result_naive is None:\n",
    "                results_naive = results_naive.append(result_naive, ignore_index=True)\n",
    "\n",
    "            result_zero = make_results_hourly(sites_data[site], 'zero', prices, index, region, cluster)      \n",
    "            #print(result_zero)\n",
    "            if not result_zero is None:\n",
    "                results_zero = results_zero.append(result_zero, ignore_index=True)\n",
    "\n",
    "            result_increased_10 = make_results_hourly(sites_data[site], 'increased_10', prices, index, region, cluster)      \n",
    "            #print(result_increased_10)\n",
    "            if not result_increased_10 is None:\n",
    "                results_increased_10 = results_increased_10.append(result_increased_10, ignore_index=True)\n",
    "\n",
    "            result_increased_20 = make_results_hourly(sites_data[site], 'increased_20', prices, index, region, cluster)      \n",
    "            #print(result_increased_20)\n",
    "            if not result_increased_20 is None:\n",
    "                results_increased_20 = results_increased_20.append(result_increased_20, ignore_index=True)\n",
    "\n",
    "            result_increased_30 = make_results_hourly(sites_data[site], 'increased_30', prices, index, region, cluster)      \n",
    "            #print(result_increased_30)\n",
    "            if not result_increased_30 is None:\n",
    "                results_increased_30 = results_increased_30.append(result_increased_30, ignore_index=True)\n",
    "\n",
    "            result_increased_40 = make_results_hourly(sites_data[site], 'increased_40', prices, index, region, cluster)      \n",
    "            #print(result_increased_40)\n",
    "            if not result_increased_40 is None:\n",
    "                results_increased_40 = results_increased_40.append(result_increased_40, ignore_index=True)\n",
    "\n",
    "            result_decreased_10 = make_results_hourly(sites_data[site], 'decreased_10', prices, index, region, cluster)      \n",
    "            #print(result_decreased_10)\n",
    "            if not result_decreased_10 is None:\n",
    "                results_decreased_10 = results_decreased_10.append(result_decreased_10, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        sites_data[site]['results_real'] = results_real\n",
    "        sites_data[site]['results_raw'] = results_raw\n",
    "        sites_data[site]['results_naive'] = results_naive\n",
    "        sites_data[site]['results_zero'] = results_zero\n",
    "        sites_data[site]['results_increased_10'] = results_increased_10\n",
    "        sites_data[site]['results_increased_20'] = results_increased_20\n",
    "        sites_data[site]['results_increased_30'] = results_increased_30\n",
    "        sites_data[site]['results_increased_40'] = results_increased_40\n",
    "        sites_data[site]['results_decreased_10'] = results_decreased_10\n",
    "\n",
    "\n",
    "        print(f'{site} - Results daily: Ok!')\n",
    "\n",
    "    # print(sites_data[site]['results_real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uce_resources import save_results, format_excel\n",
    "\n",
    "results_daily = pd.concat([results_real, results_raw, results_naive, results_zero, results_increased_10, results_increased_20, \n",
    "                           results_increased_30, results_increased_40, results_decreased_10], ignore_index=True, axis=0)\n",
    "\n",
    "# min_day = results_daily.first_date.min().day\n",
    "# max_day = results_daily.last_date.max().day\n",
    "\n",
    "with pd.ExcelWriter(target_folder + 'uce_daily_hourly_{}_{}_UAH.xlsx'.format(target_year, target_month), engine=\"openpyxl\") as  writer:\n",
    "    results_daily.to_excel(writer, 'results_daily')\n",
    "\n",
    "#  writer.save()\n",
    "# format_excel(writer, results_daily).save()\n",
    "\n",
    "print('Saving results: ok!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uce_daily",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "086c78819d29cde2722290ef7b1822e29db9962e5a12d827023861b18bf338dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
