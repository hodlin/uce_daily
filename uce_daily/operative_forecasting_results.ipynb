{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import pytz\n",
    "import time\n",
    "import calendar\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "\n",
    "from uce_resources import get_mms_data, get_applied_forecast, get_current_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings.sites import ceg as sites_list\n",
    "\n",
    "target_year = 2022\n",
    "target_month = 9\n",
    "forecasts_types = ['real']\n",
    "\n",
    "target_folder = 'data/results/{}-{:0>2}/'.format(target_year, target_month)\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "# sites_list = ['Pohrebyshche']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\o.babenko\\.conda\\envs\\uce_daily\\lib\\site-packages\\ipykernel_launcher.py:8: SAWarning: Did not recognize type 'point' of column 'location'\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy.pool import NullPool\n",
    "from sqlalchemy.sql import select, and_\n",
    "from settings.db import DO_URL\n",
    "\n",
    "engine_source = create_engine(DO_URL, poolclass=NullPool)\n",
    "metadata_source = MetaData()\n",
    "metadata_source.reflect(bind=engine_source)\n",
    "\n",
    "\n",
    "from settings.db import WAREHOSUE_URL\n",
    "\n",
    "engine_warehouse = create_engine(WAREHOSUE_URL, poolclass=NullPool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bar: ок! Processing took 3.78 seconds\n",
      "Verkhivka: ок! Processing took 2.64 seconds\n",
      "Balky: ок! Processing took 2.6 seconds\n",
      "Sharhorod_1: ок! Processing took 2.6 seconds\n",
      "Chechelnyk_1: ок! Processing took 2.62 seconds\n",
      "Chechelnyk_2: ок! Processing took 2.54 seconds\n",
      "Stanislavchyk: ок! Processing took 2.6 seconds\n",
      "Kopaihorod: ок! Processing took 2.48 seconds\n",
      "Cherniatka: ок! Processing took 2.47 seconds\n",
      "Hlybochok_1: ок! Processing took 2.32 seconds\n",
      "Hlybochok_2.1: ок! Processing took 3.2 seconds\n",
      "Hlybochok_2.2: ок! Processing took 2.5 seconds\n",
      "Pohrebyshche: ок! Processing took 2.53 seconds\n",
      "Bilashky: ок! Processing took 2.53 seconds\n",
      "Porohy: ок! Processing took 2.5 seconds\n",
      "Hnatkiv: ок! Processing took 2.8 seconds\n",
      "Myroliubivka: ок! Processing took 2.63 seconds\n",
      "Kyselivka: ок! Processing took 2.62 seconds\n",
      "Poniativka: ок! Processing took 2.44 seconds\n",
      "Kostohryzove: ок! Processing took 2.52 seconds\n",
      "Bilozerka: ок! Processing took 2.6 seconds\n",
      "Mykolaivka: ок! Processing took 2.49 seconds\n",
      "Komyshany_1: ок! Processing took 2.41 seconds\n",
      "Komyshany_2: ок! Processing took 2.53 seconds\n",
      "Velihen: ок! Processing took 2.44 seconds\n",
      "Veliton: ок! Processing took 2.63 seconds\n",
      "Mala_Lepetykha: ок! Processing took 2.38 seconds\n",
      "Rubanivka: ок! Processing took 2.58 seconds\n",
      "Oleshky_2: ок! Processing took 2.82 seconds\n",
      "Oleshky_1: ок! Processing took 2.82 seconds\n",
      "Liubymivka: ок! Processing took 2.32 seconds\n",
      "Kachkarivka: ок! Processing took 2.97 seconds\n",
      "Vasylivka: ок! Processing took 2.29 seconds\n",
      "Afanasiivka: ок! Processing took 2.51 seconds\n",
      "Novokondakove: ок! Processing took 2.38 seconds\n",
      "Bazaltova: ок! Processing took 2.45 seconds\n",
      "Yelanets_1: ок! Processing took 2.33 seconds\n",
      "Yelanets_2: ок! Processing took 2.49 seconds\n",
      "Inhulets_1: ок! Processing took 2.51 seconds\n",
      "Inhulets_2: ок! Processing took 2.46 seconds\n",
      "Bereznehuvate: ок! Processing took 2.67 seconds\n",
      "Teplychna: ок! Processing took 2.41 seconds\n",
      "Solone: ок! Processing took 2.3 seconds\n",
      "Stepnohirsk: ок! Processing took 2.28 seconds\n",
      "Balivka: ок! Processing took 2.23 seconds\n",
      "Dibrovka: ок! Processing took 2.44 seconds\n",
      "Kulevcha: ок! Processing took 2.4 seconds\n"
     ]
    }
   ],
   "source": [
    "sites_data = list()\n",
    "\n",
    "with engine_source.connect() as connection:\n",
    "        \n",
    "    for site in sites_list:\n",
    "        start = time.time()\n",
    "        # print('-'*50)\n",
    "        # print(site)\n",
    "        site_data = dict()\n",
    "\n",
    "        sites_table = metadata_source.tables['sites']\n",
    "        list_to_select = [\n",
    "            sites_table.c.id, \n",
    "            sites_table.c.legal_entity, \n",
    "            sites_table.c.location, \n",
    "            sites_table.c.region, \n",
    "            sites_table.c.cluster,\n",
    "            sites_table.c.installed_capacity_dc,\n",
    "            sites_table.c.grid_capacity \n",
    "            ]\n",
    "        query = select(list_to_select).where(sites_table.c.displayable_name == site)\n",
    "        site_id_response = connection.execute(query).fetchall()[0]\n",
    "\n",
    "        site_id = site_id_response[0]\n",
    "        legal_entity_id = site_id_response[1]\n",
    "        location = site_id_response[2]\n",
    "        region = site_id_response[3]\n",
    "        cluster = site_id_response[4]\n",
    "        capacity_dc = site_id_response[5]\n",
    "        \n",
    "        with engine_warehouse.connect() as connection_warehouse:\n",
    "            query = f\"\"\"\n",
    "            SELECT grid_capacity from dim_site\n",
    "            WHERE site_name = '{site}';\n",
    "            \"\"\"\n",
    "            response = connection_warehouse.execute(query).fetchall()[0]\n",
    "            \n",
    "        grid_capacity = response[0]\n",
    "\n",
    "        latitude, longitude = map(float, location.replace('(', '').replace(')', '').split(','))\n",
    "        mms_data, mms_version = get_mms_data(site_id, \n",
    "                                             target_year, target_month, \n",
    "                                             connection, metadata_source.tables['mms_data'], include_prev=True,)\n",
    "        mms_data.columns = ['yield']\n",
    "        # print(mms_data)\n",
    "        # print('MMS data | {} version | of | {} records |'.format(mms_version, len(mms_data)))\n",
    "        # print(mms_data.index.max())\n",
    "\n",
    "        applied_forecast = get_applied_forecast(site_id, target_year, target_month, \n",
    "                                                connection=connection, db_table=metadata_source.tables['forecasts_applied'])\n",
    "        applied_forecast.columns = ['forecast']\n",
    "        # print('Forecast data of | {} records |'.format(len(applied_forecast)))\n",
    "        # print(applied_forecast.index.max())\n",
    "        # print(applied_forecast)\n",
    "\n",
    "        current_forecast_dates = [applied_forecast.index.max() + dt.timedelta(days=x) for x in range(1,4)]\n",
    "        current_forecast = get_current_forecast(site_id, current_forecast_dates, connection, metadata_source.tables['forecasts_applied']).to_frame()\n",
    "        current_forecast.columns = ['forecast']\n",
    "\n",
    "        # print(current_forecast.index.min())\n",
    "        # print(current_forecast.index.max())\n",
    "\n",
    "        forecast = pd.concat([applied_forecast, current_forecast])\n",
    "        forecast_data = pd.concat([forecast, mms_data.loc[mms_data.index >= forecast.index.min()]], axis=1, join='outer').reindex(columns=['yield', 'forecast'])\n",
    "\n",
    "        site_series = pd.Series(index=forecast_data.index, data=site)\n",
    "        latitude_series = pd.Series(index=forecast_data.index, data=latitude)\n",
    "        longitude_series = pd.Series(index=forecast_data.index, data=longitude)\n",
    "        region_series = pd.Series(index=forecast_data.index, data=region)\n",
    "        cluster_series = pd.Series(index=forecast_data.index, data=cluster)\n",
    "        capacity_dc_series = pd.Series(index=forecast_data.index, data=capacity_dc)\n",
    "        grid_capacity_series = pd.Series(index=forecast_data.index, data=grid_capacity)\n",
    "\n",
    "        site_data = pd.concat([\n",
    "                    site_series, \n",
    "                    latitude_series, \n",
    "                    longitude_series,\n",
    "                    region_series, \n",
    "                    cluster_series,\n",
    "                    capacity_dc_series,\n",
    "                    grid_capacity_series\n",
    "                ], \n",
    "                axis=1\n",
    "            )\n",
    "        site_data.columns = ['site', 'latitude', 'longitude', 'region', 'cluster', 'capacity_dc', 'grid_capacity']                       \n",
    "        site_data['date'] = site_data.index.strftime('%Y-%m-%d')\n",
    "        site_data['hour'] = site_data.index.hour + 1\n",
    "        site_data['datetime'] = site_data.index.strftime('%Y-%m-%dT%H:%M')\n",
    "        site_data['datetime_tz'] = site_data.index.tz_localize(pytz.utc).tz_convert(pytz.timezone('europe/kiev')).strftime('%Y-%m-%dT%H:%M%z')\n",
    "        \n",
    "        site_data = pd.concat([site_data, forecast_data], axis=1)\n",
    "\n",
    "        site_data['error'] = site_data['yield'] - site_data['forecast']\n",
    "        site_data['error_positive'] = site_data['error'].apply(lambda x: x * (x >= 0))\n",
    "        site_data['error_negative'] = site_data['error'].apply(lambda x: x * (x < 0))\n",
    "        site_data['error_abs'] = site_data['error'].apply(abs)\n",
    "        site_data['error_type'] = site_data['error'].apply(lambda x: 'negative' if x < 0 else 'positive')\n",
    "        \n",
    "        sites_data.append(site_data)\n",
    "        end = time.time()\n",
    "\n",
    "        print('{}: ок! Processing took {} seconds'.format(site, round(end - start, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(sites_data, ignore_index=True).fillna(0)\n",
    "data = data.drop_duplicates(keep='first')\n",
    "data.to_csv(target_folder + 'mart_operative_forecasting_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [site, latitude, longitude, region, cluster, capacity_dc, grid_capacity, date, hour, datetime, datetime_tz, yield, forecast, error, error_positive, error_negative, error_abs, error_type]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "yield      NaN\n",
       "forecast   NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_26 = data.copy()\n",
    "# data_26 = data.loc[data.date == '2022-03-26']\n",
    "site = 'Myroliubivka'\n",
    "print(data_26.loc[(data_26.site == site) & (data_26['yield'] <= 0) & (data_26['forecast'] < 0)])\n",
    "data_26.loc[(data_26.site == site) & (data_26['yield'] <= 0) & (data_26['forecast'] < 0)][['yield', 'forecast']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting data to data mart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = data.copy()\n",
    "tuples_full = [tuple(x) for x in df_full.to_numpy()]\n",
    "# print(tuples_full[-2:])\n",
    "columns = list(df_full.columns)\n",
    "\n",
    "columns_unique = [columns[0], *columns[5:7]]\n",
    "# print(columns_unique)\n",
    "\n",
    "df_update = df_full.copy().drop(columns=columns_unique)\n",
    "tuples_update = [tuple(x) for x in df_update.to_numpy()]\n",
    "columns_update = list(df_update.columns)\n",
    "# print(columns_update)\n",
    "# SQL query to execute\n",
    "query_1 = 'INSERT INTO mart_operative_forecasting_result({}) VALUES {}'.format(','.join(columns), str(tuples_full).replace('[', '').replace(']', ''))\n",
    "query_2 = '''\n",
    "ON CONFLICT (site, date, hour) \n",
    "DO UPDATE SET\n",
    "latitude = excluded.latitude,\n",
    "longitude = excluded.longitude,\n",
    "region = excluded.region,\n",
    "cluster = excluded.cluster,\n",
    "datetime = excluded.datetime,\n",
    "datetime_tz = excluded.datetime_tz,\n",
    "yield = excluded.yield,\n",
    "forecast = excluded.forecast,\n",
    "error = excluded.error,\n",
    "error_positive = excluded.error_positive,\n",
    "error_negative = excluded.error_negative,\n",
    "error_abs = excluded.error_abs,\n",
    "error_type = excluded.error_type,\n",
    "capacity_dc = excluded.capacity_dc,\n",
    "grid_capacity = excluded.grid_capacity;'''\n",
    "# print(query_1, query_2)\n",
    "with engine_warehouse.connect() as connection:\n",
    "    connection.execute(query_1 + '\\n' + query_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('uce_daily')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f6094ec2d56ebdaae3d9c77f7ab32436394f8c6f1a90f5df9f6a393f513a0f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
